{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepares tax-related data from IPUMS for analysis. Includes cleaning, reshaping, and representative parent generation (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set the directories for raw and intermediate data\n",
    "raw_data_root = \"/Users/aneeshtekulapally/Documents/College/Thesis/Code/Data/IPUMS\" # Path to the folder containing downloaded data from IPUMS\n",
    "clean_data_root = \"/Users/aneeshtekulapally/Documents/College/Thesis/Code/Data/Clean\" # Path to the folder that will contain the cleaned data\n",
    "\n",
    "# # File paths for input and output\n",
    "mtr_in_file = f\"{intermed_root}/NTR_cleaned.csv\"\n",
    "mtr_out_file = f\"{intermed_root}/nominal_tax_rates\"\n",
    "\n",
    "# Year ranges and flags\n",
    "\n",
    "census_start, census_end = 1940, 2020\n",
    "cps_start, cps_end = 1970, 2023\n",
    "\n",
    "# Flags for processing steps, just for compartmentalizing computing \n",
    "adjust_1940 = True\n",
    "clean_census = True\n",
    "clean_cps = True\n",
    "reshape_census = True\n",
    "gen_rep_parents = True\n",
    "reshape_cps = True\n",
    "\n",
    "# to reshape marginal tax rate \n",
    "#reshape_mtr = True\n",
    "\n",
    "# Additional variables for representative parents generation\n",
    "partype = \"richer\" # options: richer, older, mother, father\n",
    "pargender = None # options: male, female, None for no restriction\n",
    "\n",
    "exclude_gq = \"match_cps\" #options: all, none, match_cps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusts income categories within the 1940 Census data to align with the income categories present in the 1950 Census."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "if adjust_1940:\n",
    "    # Load the 1950 Census data\n",
    "    census1950_df = pd.read_csv(f\"{raw_data_root}/Census1950_raw.csv\")\n",
    "    census1950_df.sort_values(by=['SERIAL', 'PERNUM'], inplace=True)\n",
    "    \n",
    "    # Replace specified values with NaN (missing values)\n",
    "    census1950_df['INCWAGE'].replace(999999, np.nan, inplace=True)\n",
    "    census1950_df['INCTOT'].replace(9999999, np.nan, inplace=True)\n",
    "    census1950_df['FTOTINC'].replace([9999999, 9999998], np.nan, inplace=True)\n",
    "    \n",
    "    # Replace FTOTINC missing values with inctot where applicable\n",
    "    census1950_df.loc[census1950_df['FTOTINC'].isna(), 'FTOTINC'] = census1950_df['INCTOT']\n",
    "    \n",
    "    # Keep rows with non-missing FTOTINC and incwage, and FTOTINC >= 0\n",
    "    census1950_df.dropna(subset=['FTOTINC', 'INCWAGE'], inplace=True)\n",
    "    census1950_df = census1950_df[census1950_df['FTOTINC'] >= 0]\n",
    "    \n",
    "    # Calculate non-wage income\n",
    "    census1950_df['NONWAGE'] = census1950_df['FTOTINC'] - census1950_df['INCWAGE']\n",
    "    \n",
    "    # Deflate to 1939 Dollars using CPI\n",
    "    census1950_df['NONWAGE'] *= 0.58\n",
    "    \n",
    "    # Replace specific occupation and race codes with NaN\n",
    "    census1950_df['OCC1950'].replace([999, 997], np.nan, inplace=True)\n",
    "    census1950_df['RACE'].replace(list(range(3, max(census1950_df['RACE'])+1)), 3, inplace=True)\n",
    "    \n",
    "    # Generate incnonwg categories based on nonwage income\n",
    "    census1950_df['INCNONWG'] = pd.cut(census1950_df['NONWAGE'], bins=[-np.inf, 0, 50, np.inf], labels=[\"missing\", 1, 2])\n",
    "    \n",
    "    # Collapse the dataframe by mean nonwage for groups\n",
    "    collapsed_df = census1950_df.groupby(['OCC1950', 'CLASSWKR', 'RACE', 'INCNONWG'])['NONWAGE'].mean().reset_index()\n",
    "    collapsed_df['NONWAGE'] = collapsed_df['NONWAGE'].round()\n",
    "    \n",
    "    # Save the adjusted data for 1940\n",
    "    collapsed_df.to_csv(f\"{raw_data_root}/inc_adj_for_1940.csv\", index=False)\n",
    "    \n",
    "    # Load the 1940 Census data\n",
    "    census1940_df = pd.read_csv(f\"{raw_data_root}/Census1940_raw.csv\")\n",
    "    \n",
    "    # Replace specific occupation and race codes with NaN\n",
    "    census1940_df['OCC1950'].replace([999, 997], np.nan, inplace=True)\n",
    "    census1940_df['RACE'].replace(list(range(3, max(census1940_df['RACE'])+1)), 3, inplace=True)\n",
    "    \n",
    "    # Merge the 1940 dataset with the collapsed dataset\n",
    "    merged_df = pd.merge(census1940_df, collapsed_df, on=['OCC1950', 'CLASSWKR', 'RACE', 'INCNONWG'], how='left')\n",
    "    \n",
    "    # Adjust nonwage based on incnonwg and merge status\n",
    "    # Assuming 'missing' is a category for missing INCNONWG values and actual NaNs might exist\n",
    "    merged_df.loc[(merged_df['INCNONWG'].isnull()) | (merged_df['OCC1950'].isna()), 'NONWAGE'] = np.nan\n",
    "    # For rows where INCNONWG == 1 and NONWAGE is not NaN, set NONWAGE to 50\n",
    "    merged_df.loc[(merged_df['INCNONWG'] == '1') & (merged_df['NONWAGE'].notna()), 'NONWAGE'] = 50\n",
    "\n",
    "    # Save the merged and adjusted 1940 Census data\n",
    "    merged_df.to_csv(f\"{clean_data_root}/Census1940_raw_adjusted.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if clean_census:\n",
    "    for year in range(census_start, census_end + 1, 10):\n",
    "        os.chdir(raw_data_root)\n",
    "        df = pd.read_csv(f\"Census{year}_raw.csv\")\n",
    "\n",
    "        # Dropping observations based on missing values\n",
    "        df.dropna(subset=['YEAR', 'PERNUM', 'SERIAL', 'SEX', 'AGE'], inplace=True)\n",
    "\n",
    "        # Dropping observations based on 'gq' values\n",
    "        if exclude_gq == \"all\":\n",
    "            df = df[df['GQ'] <= 1]\n",
    "        elif exclude_gq == \"match_cps\":\n",
    "            df = df[~df['GQTYPE'].isin([1, 2, 3, 4, 6])]\n",
    "\n",
    "        # Dropping variables if they exist\n",
    "        for drop_var in ['DATADNUM', 'CLUSTER', 'STRATA', 'RELATED', 'PERWT', 'GQ', 'GQTYPE']:\n",
    "            if drop_var in df.columns:\n",
    "                df.drop(columns=[drop_var], inplace=True)\n",
    "\n",
    "        # Creating variables if they don't exist\n",
    "        for required_var in ['INCTOT', 'FTOTINC', 'INCWELFR', 'INCSUPP']:\n",
    "            if required_var not in df.columns:\n",
    "                df[required_var] = np.nan\n",
    "\n",
    "        # Replacing certain values with NaN based on conditions\n",
    "        df['INCWAGE'].replace({999999: np.nan, 999998: np.nan}, inplace=True)\n",
    "        if year > 1940:\n",
    "            df['INCTOT'].replace({9999999: np.nan}, inplace=True)\n",
    "            df['FTOTINC'].replace({9999999: np.nan, 9999998: np.nan}, inplace=True)\n",
    "        if year > 1960:\n",
    "            df['INCWELFR'].replace({99999: np.nan}, inplace=True)\n",
    "        if year > 1990:\n",
    "            df['INCSUPP'].replace({99999: np.nan}, inplace=True)\n",
    "        if year >= 2000:\n",
    "            df['INCWELFR'] = np.where(df['INCSUPP'].notna(), df['INCWELFR'] + df['INCSUPP'], df['INCWELFR'])\n",
    "\n",
    "        # Generating a unique ID and sorting\n",
    "        df['id'] = 100 * df['SERIAL'] + df['PERNUM']\n",
    "        df.sort_values(by=['YEAR', 'id'], inplace=True)\n",
    "\n",
    "        # Changing directory and saving the cleaned file\n",
    "        os.chdir(clean_data_root)\n",
    "        df.to_csv(f\"census{year}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clean_cps:\n",
    "    # Change directory to raw data root\n",
    "    os.chdir(raw_data_root)\n",
    "    \n",
    "    # Load the data\n",
    "    cps_data = pd.read_csv(\"CPS_1962to2023.csv\")\n",
    "    \n",
    "    # Merge with cps_swapvalues data\n",
    "    cps_swapvalues = pd.read_csv(\"cps_swapvalues.csv\")\n",
    "    cps_data = cps_data.merge(cps_swapvalues, on=[\"YEAR\", \"SERIAL\", \"PERNUM\"], how=\"left\", indicator=False)\n",
    "    \n",
    "    # Variables to be replaced with NaN where value is 99999\n",
    "    vlist = ['INCALIM', 'INCALOTH', 'INCASIST', 'INCCHILD','INCDRT',\n",
    "            'INCEDUC','INCGOV','INCIDR','INCINT','INCOTHER','INCRENT','INCSS','INCSSI','INCUNEMP','INCVET','INCWELFR','INCWKCOM']\n",
    "    for var in vlist:\n",
    "        cps_data[var] = cps_data[var].replace(99999, np.nan)\n",
    "    \n",
    "    # Variables to be replaced with NaN where value is 999999\n",
    "    vrbls = [\"INCDISAB\", \"INCDIVID\", \"INCLONGJ\", \"INCRETIR\", \"INCSURV\", \"OINCBUS\", \"OINCFARM\", \"FTOTVAL\"]\n",
    "    for var in vrbls:\n",
    "        cps_data[var] = cps_data[var].replace(999999, np.nan)\n",
    "    \n",
    "    # Variables to be replaced with NaN where value is 9999999 or 9999998\n",
    "    vrs = [\"INCBUS\", \"INCFARM\", \"INCWAGE\", \"OINCWAGE\"]\n",
    "    for var in vrs:\n",
    "        cps_data[var] = cps_data[var].replace([9999999, 9999998], np.nan)\n",
    "    \n",
    "    # Special cases\n",
    "    cps_data[\"INCTOT\"] = cps_data[\"INCTOT\"].replace([99999999, 99999998], np.nan)\n",
    "    cps_data[\"SPLOC\"] = cps_data[\"SPLOC\"].fillna(0).astype(int)\n",
    "    cps_data.loc[cps_data[\"SPLOC\"] < 0, \"sploc\"] = 0\n",
    "    \n",
    "    # Swap values where applicable\n",
    "    vars_to_swap = [\"INCWAGE\", \"INCBUS\", \"INCFARM\", \"INCSS\", \"INCWELFR\", \"INCGOV\", \"INCALOTH\", \"INCRETIR\", \"INCSSI\", \"INCDRT\", \"INCINT\", \"INCUNEMP\", \"INCWKCOM\", \"INCVET\", \"INCSURV\", \"INCDISAB\", \"INCDIVID\", \"INCRENT\", \"INCEDUC\", \"INCCHILD\", \"INCALIM\", \"INCASIST\", \"INCOTHER\", \"INCLONGJ\", \"OINCBUS\", \"OINCFARM\", \"OINCWAGE\"]\n",
    "    for var in vars_to_swap:\n",
    "        swap_var = f\"{var}_SWAP\"\n",
    "        condition = (~pd.isna(cps_data[swap_var])) & (cps_data[swap_var] != 0)\n",
    "        cps_data.loc[condition, var] = cps_data.loc[condition, swap_var]\n",
    "    \n",
    "    # Define lists for row total calculations\n",
    "    list75 = ['INCWAGE', 'INCBUS', 'INCFARM', 'INCSS', 'INCWELFR', 'INCIDR', 'INCALOTH', 'INCGOV']\n",
    "    list87 = ['INCWAGE', 'INCBUS', 'INCFARM', 'INCSS', 'INCWELFR', 'INCRETIR', 'INCSSI', 'INCINT', 'INCDRT', 'INCALOTH', 'INCGOV']\n",
    "    list88 = ['OINCWAGE', 'OINCBUS', 'OINCFARM', 'INCSS', 'INCWELFR', 'INCRETIR', 'INCSSI', 'INCINT', 'INCLONGJ', 'INCUNEMP', 'INCWKCOM', 'INCVET', 'INCSURV', 'INCDISAB', 'INCDIVID', 'INCRENT', 'INCEDUC', 'INCCHILD', 'INCALIM', 'INCASIST', 'INCOTHER']\n",
    "\n",
    "    # Calculate row totals for specified years\n",
    "    cps_data['inctotal75'] = cps_data[list75].sum(axis=1).where(cps_data['YEAR'].between(1968, 1975), 0)\n",
    "    cps_data['inctotal87'] = cps_data[list87].sum(axis=1).where(cps_data['YEAR'].between(1976, 1987), 0)\n",
    "    cps_data['inctotal88'] = cps_data[list88].sum(axis=1).where(cps_data['YEAR'] >= 1988, 0)\n",
    "    cps_data['INCTOT_NO_TOP'] = cps_data[['inctotal75', 'inctotal87', 'inctotal88']].sum(axis=1)\n",
    "    \n",
    "    cps_data.rename(columns={'INCTOT': 'INCTOT_TOPCODED', 'INCTOT_NO_TOP': 'INCTOT'}, inplace=True)\n",
    "    cps_data[\"INCWELFR\"] = np.where((cps_data[\"YEAR\"] >= 1976) & (~cps_data[\"INCSSI\"].isna()), cps_data[\"INCWELFR\"] + cps_data[\"INCSSI\"], cps_data[\"INCWELFR\"])\n",
    "    \n",
    "    # Generating ids\n",
    "    cps_data[\"ID\"] = 100 * cps_data[\"SERIAL\"] + cps_data[\"PERNUM\"]\n",
    "    cps_data[\"MOM_ID\"] = np.where((cps_data[\"MOMLOC\"].notna()) & (cps_data[\"MOMLOC\"] > 0), 100 * cps_data[\"SERIAL\"] + cps_data[\"MOMLOC\"], np.nan)\n",
    "    cps_data[\"POP_ID\"] = np.where((cps_data[\"POPLOC\"].notna()) & (cps_data[\"POPLOC\"] > 0), 100 * cps_data[\"SERIAL\"] + cps_data[\"POPLOC\"], np.nan)\n",
    "    \n",
    "    # Renaming weights\n",
    "    cps_data.rename(columns={\"ASECWT\": \"WTSUPP\", \"ASECWTH\": \"HWTSUPP\"}, inplace=True)\n",
    "    \n",
    "    # Keeping specified columns\n",
    "    columns_to_keep = ['YEAR', 'ID', 'MARST', 'SERIAL', 'MOM_ID', 'POP_ID', 'SPLOC', 'WTSUPP', 'BPL', 'AGE', 'SEX', 'INCTOT', 'INCTOT_TOPCODED', 'FTOTVAL', 'INCWAGE', 'INCWELFR', 'INCSSI', 'NCHILD', 'FAMSIZE']\n",
    "    cps_data = cps_data[columns_to_keep]\n",
    "    \n",
    "    # Compressing (in pandas, this usually means converting data types for efficiency)\n",
    "    cps_data = cps_data.convert_dtypes()\n",
    "    \n",
    "    # Change directory to intermediate data root and save\n",
    "    os.chdir(clean_data_root)\n",
    "    cps_data.to_csv(\"CPS_intermed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/usr/local/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "if reshape_census:\n",
    "    for year in range(census_start, census_end + 1, 10):\n",
    "        # Reshape data into couples\n",
    "        os.chdir(clean_data_root)\n",
    "        df = pd.read_csv(f\"census{year}.csv\")\n",
    "        \n",
    "        # Processing singles\n",
    "        df_singles = df[df['SPLOC'] == 0]\n",
    "        df_singles.sort_values(by=['YEAR', 'id'], inplace=True)\n",
    "        census_singles = f\"census_singles_{year}.csv\"\n",
    "        df_singles.to_csv(census_singles)\n",
    "\n",
    "        # Processing spouses\n",
    "        df = pd.read_csv(f\"census{year}.csv\")\n",
    "        df_spouses = df[(df['SPLOC'].notnull()) & (df['SPLOC'] > 0)]\n",
    "        df_spouses['ID_SPOUSE'] = 100 * df_spouses['SERIAL'] + df_spouses['SPLOC']\n",
    "        df_spouses.rename(columns={'id': 'OWNID', 'INCWAGE': 'INCWAGE_SPOUSE', 'AGE': 'AGE_SPOUSE', 'SEX': 'SEX_SPOUSE', 'BPL': 'BPL_SPOUSE', 'INCWELFR': 'INCWELFR_SPOUSE', 'INCSUPP': 'INCSUPP_SPOUSE', 'INCTOT': 'INCTOT_SPOUSE'}, inplace=True)\n",
    "        df_spouses = df_spouses[['YEAR', 'ID_SPOUSE', 'AGE_SPOUSE', 'OWNID', 'SEX_SPOUSE', 'BPL_SPOUSE', 'INCWAGE_SPOUSE', 'INCSUPP_SPOUSE', 'INCTOT_SPOUSE', 'INCWELFR_SPOUSE']]\n",
    "        census_spouses = f\"census_spouses_{year}.csv\"\n",
    "        df_spouses.to_csv(census_spouses)\n",
    "\n",
    "        # Merging spouses\n",
    "        df = pd.read_csv(f\"census{year}.csv\")\n",
    "        df.rename(columns={'id': 'ID_SPOUSE'}, inplace=True)\n",
    "        df.sort_values(by=['YEAR', 'SERIAL', 'PERNUM'], inplace=True)\n",
    "        df_merged = pd.merge(df, df_spouses, on=['YEAR', 'ID_SPOUSE'], how='inner').drop_duplicates()\n",
    "        df_merged['dup_tag'] = df_merged.groupby('SERIAL').cumcount() + 1\n",
    "        df_merged = df_merged[(df_merged['dup_tag'] % 2) == 1]\n",
    "        df_merged.rename(columns={'ID_SPOUSE': 'id', 'OWNID': 'ID_SPOUSE'}, inplace=True)\n",
    "        \n",
    "        # Appending singles and saving\n",
    "        df_final = pd.concat([df_merged, df_singles]).sort_values(by=['YEAR', 'id'])\n",
    "        if 'NONWAGE' not in df_final.columns:\n",
    "            df_final['NONWAGE'] = np.nan\n",
    "        \n",
    "        df_final.to_csv(f\"census{year}_couples.csv\")\n",
    "\n",
    "        # Generating identifiers for parents based on paternal and maternal locations\n",
    "        df = pd.read_csv(f\"census{year}_couples.csv\")\n",
    "        df['ID_FATHER'] = np.where(df['POPLOC'].notnull() & (df['POPLOC'] > 0), 100 * df['SERIAL'] + df['POPLOC'], np.nan)\n",
    "        df['ID_MOTHER'] = np.where(df['MOMLOC'].notnull() & (df['MOMLOC'] > 0), 100 * df['SERIAL'] + df['MOMLOC'], np.nan)\n",
    "        df['ID_PARENT'] = df['ID_MOTHER']\n",
    "        df['ID_PARENT'].fillna(df['ID_FATHER'], inplace=True)\n",
    "        \n",
    "        df.rename(columns={'id': 'ID_CHILD',\n",
    "                           'AGE': 'AGE_CHILD',\n",
    "                           'SEX': 'SEX_CHILD',\n",
    "                           'BPL': 'BPL_CHILD'}, inplace=True)\n",
    "        df_children = df[['YEAR', 'ID_PARENT', 'ID_CHILD', 'AGE_CHILD', 'SEX_CHILD', 'BPL_CHILD']].dropna(subset=['ID_PARENT'])\n",
    "        \n",
    "        # Save children data for later merge\n",
    "        census_kids = f\"census_kids_{year}.csv\"\n",
    "        df_children.to_csv(census_kids)\n",
    "        \n",
    "        # Load couples data\n",
    "        df_couples = pd.read_csv(f\"census{year}_couples.csv\")\n",
    "        df_couples = df_couples[df_couples['NCHILD'] > 0]\n",
    "        \n",
    "        # Determine parent ID\n",
    "        df_couples['ID_PARENT'] = np.where(df_couples['SEX_SPOUSE'] == 2, df_couples['ID_SPOUSE'], df_couples['id'])\n",
    "        \n",
    "        # Drop duplicate parents\n",
    "        df_parents = df_couples[['ID_PARENT']].drop_duplicates()\n",
    "        \n",
    "        # Save parents data for later merge\n",
    "        census_parents = f\"census_parents_{year}.csv\"\n",
    "        df_parents.to_csv(census_parents)\n",
    "        \n",
    "        # Merge children with their parents\n",
    "        df_families = pd.merge(df_children, df_parents, on='ID_PARENT', how='inner')\n",
    "        \n",
    "        # Final compress and save\n",
    "        df_families.to_csv(f\"census{year}_families.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(clean_data_root)\n",
    "# if gen_rep_parents:\n",
    "#     for census_year in range(census_start, census_end + 1, 10): \n",
    "#         families_df = pd.read_csv(f\"census{year}_families.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['YEAR', 'ID', 'MARST', 'SERIAL', 'MOM_ID', 'POP_ID', 'SPLOC', 'WTSUPP',\n",
      "       'BPL', 'AGE', 'SEX', 'INCTOT', 'INCTOT_TOPCODED', 'FTOTVAL', 'INCWAGE',\n",
      "       'INCWELFR', 'INCSSI', 'NCHILD', 'FAMSIZE'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "os.chdir(clean_data_root)\n",
    "cps_intermed = pd.read_csv('CPS_intermed.csv')\n",
    "print(cps_intermed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "os.chdir(clean_data_root)\n",
    "if reshape_cps:\n",
    "    # Load the data into a DataFrame\n",
    "    cps_intermed = pd.read_csv('CPS_intermed.csv')\n",
    "    \n",
    "    # Generate `hasSpouse` column\n",
    "    cps_intermed['hasSpouse'] = (cps_intermed['MARST'] == 1) & (cps_intermed['SPLOC'] != 0)\n",
    "    \n",
    "    # Extract single people and put them aside for now\n",
    "    cps_singles = cps_intermed[cps_intermed['hasSpouse'] == 0].sort_values(by=['YEAR', 'ID'])\n",
    "    # Save the singles DataFrame to a temporary file\n",
    "    cps_singles_path = 'cps_singles.csv'\n",
    "    cps_singles.to_csv(cps_singles_path, index=False)\n",
    "    \n",
    "    # Extract married individuals and reshape them\n",
    "    cps_intermed = pd.read_csv('CPS_intermed.csv')\n",
    "    cps_intermed['hasSpouse'] = (cps_intermed['MARST'] == 1) & (cps_intermed['SPLOC'] != 0)\n",
    "    cps_married = cps_intermed[cps_intermed['hasSpouse'] > 0]\n",
    "    cps_married['SPOUSE_ID'] = 100 * cps_married['SERIAL'] + cps_married['SPLOC']\n",
    "    \n",
    "    # Renaming columns\n",
    "    rename_dict = {\n",
    "        'ID': 'OWNID',\n",
    "        'INCTOT': 'INCTOT_SPOUSE',\n",
    "        'INCTOT_TOPCODED': 'INCTOT_TOPCODED_SPOUSE',\n",
    "        'INCWAGE': 'INCWAGE_SPOUSE',\n",
    "        'INCWELFR': 'INCWELFR_SPOUSE',\n",
    "        'INCSSI': 'INCSSI_SPOUSE',\n",
    "        'AGE': 'AGE_SPOUSE',\n",
    "        'SEX': 'SEX_SPOUSE',\n",
    "        'BPL': 'BPL_SPOUSE'\n",
    "    }\n",
    "    cps_married.rename(columns=rename_dict, inplace=True)\n",
    "    \n",
    "    # Keeping only the first instance in each group sorted by year and serial\n",
    "    cps_married = cps_married.sort_values(by=['YEAR', 'SERIAL']).drop_duplicates(subset=['YEAR', 'SERIAL'], keep='first')\n",
    "    # Keeping specified columns\n",
    "    keep_columns = ['YEAR', 'SPOUSE_ID', 'OWNID', 'AGE_SPOUSE', 'SEX_SPOUSE', 'INCTOT_SPOUSE', 'INCWAGE_SPOUSE', 'INCWELFR_SPOUSE', 'INCSSI_SPOUSE', 'BPL_SPOUSE']\n",
    "    cps_spouses = cps_married[keep_columns]\n",
    "    \n",
    "    # Save the spouses DataFrame to a temporary file\n",
    "    cps_spouses_path = 'cps_spouses.csv'\n",
    "    cps_spouses.to_csv(cps_spouses_path, index=False)\n",
    "    \n",
    "    # Merging back with the main dataset\n",
    "    cps_intermed = pd.read_csv('CPS_intermed.csv')\n",
    "    cps_intermed['hasSpouse'] = (cps_intermed['MARST'] == 1) & (cps_intermed['SPLOC'] != 0)\n",
    "    cps_married_second = cps_intermed[cps_intermed['hasSpouse'] > 0]\n",
    "    cps_married_second.rename(columns={'ID': 'SPOUSE_ID'}, inplace=True)\n",
    "    cps_married_second = cps_married_second.sort_values(by=['YEAR', 'SERIAL']).drop_duplicates(subset=['YEAR', 'SERIAL'], keep='last')\n",
    "    \n",
    "    # Merging\n",
    "    merged_data = pd.merge(cps_married_second, cps_spouses, on=['YEAR', 'SPOUSE_ID'], how='left', validate='1:m', indicator=True)\n",
    "    merged_data = merged_data[merged_data['_merge'] == 'both'].drop(columns=['_merge'])\n",
    "    \n",
    "    # Renaming columns back\n",
    "    merged_data.rename(columns={'SPOUSE_ID': 'ID', 'OWNID': 'SPOUSE_ID'}, inplace=True)\n",
    "    \n",
    "    # Adding singles back to reshaped couple data\n",
    "    final_data = pd.concat([merged_data, cps_singles], ignore_index=True, sort=False)\n",
    "    \n",
    "    # Recoding `bpl` and generating `foreigner` and `foreigner_spouse`\n",
    "    final_data['FOREIGNER'] = np.where(final_data['BPL'] == 9900, 0, np.where(final_data['BPL'].isnull(), np.nan, 1))\n",
    "    final_data['FOREIGNER_SPOUSE'] = np.where(final_data['BPL_SPOUSE'] == 9900, 0, np.where(final_data['BPL_SPOUSE'].isnull(), np.nan, 1))\n",
    "    \n",
    "    # Updating famsize`\n",
    "    final_data['FAMSIZE'] = 1  # self\n",
    "    final_data.loc[final_data['hasSpouse'] > 0, 'FAMSIZE'] += 1  # add one for spouse\n",
    "    final_data['FAMSIZE'] += final_data['NCHILD'].fillna(0)  # add kids, assuming missing nchild implies 0\n",
    "    \n",
    "    # Dropping rows with specific conditions\n",
    "    final_data = final_data.drop(final_data[(final_data['FTOTVAL'].isnull()) & (final_data['INCTOT'].isnull()) & (final_data['INCTOT_SPOUSE'].isnull())].index)\n",
    "    \n",
    "    # Keeping specified columns and sorting\n",
    "    final_columns = ['YEAR', 'ID', 'MARST', 'NCHILD', 'SPOUSE_ID', 'MOM_ID', 'POP_ID', 'SEX', 'SEX_SPOUSE', 'AGE', 'AGE_SPOUSE', 'FOREIGNER', 'FOREIGNER_SPOUSE', 'FAMSIZE', 'WTSUPP', 'FTOTVAL', 'INCTOT', 'INCTOT_SPOUSE', 'INCWAGE', 'INCWAGE_SPOUSE', 'INCWELFR', 'INCWELFR_SPOUSE', 'INCSSI', 'INCSSI_SPOUSE']\n",
    "\n",
    "    final_data = final_data[final_columns].sort_values(by=['YEAR', 'ID'])\n",
    "    \n",
    "    # Compressing and saving the final DataFrame\n",
    "    final_data_path = 'CPS_clean.csv'\n",
    "    final_data.to_csv(final_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(clean_data_root)\n",
    "df = pd.read_csv(\"CPS_clean.csv\")\n",
    "num_rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7689156\n"
     ]
    }
   ],
   "source": [
    "print(num_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
